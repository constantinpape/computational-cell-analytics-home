<!DOCTYPE html>
<!--
    Plain-Academic by Vasilios Mavroudis
    Released under the Simplified BSD License/FreeBSD (2-clause) License.
    https://github.com/mavroudisv/plain-academic
-->

<html lang="en">
<head>
  <title>Constantin Pape - Computational Cell Analytics</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.0/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js"></script>
  <link href='https://fonts.googleapis.com/css?family=Oswald:700' rel='stylesheet' type='text/css'>
</head>
<body>


<!-- Navigation -->
	<nav class="navbar navbar-inverse navbar-static-top" role="navigation">
	  <div class="container">
		<div class="navbar-header">
		  <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
						<span class="sr-only">Toggle navigation</span>
						<span class="icon-bar"></span>
						<span class="icon-bar"></span>
						<span class="icon-bar"></span>
					</button>
		</div>

		<!-- Collect the nav links, forms, and other content for toggling -->
		<div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
		  <ul class="nav navbar-nav">
				  <li><a href="index.html">Home</a></li>
				  <li><a href="#research">Research</a></li>
				  <li><a href="#teaching">Teaching</a></li>
				  <li><a href="#publications">Publications</a></li> 
				  <li><a href="#cv">CV</a></li> 
		  </ul>
		</div>
	  </div>
	</nav>
  
  <!-- Page Content -->
    <div class="container">

        <div class="row">

            <!-- Entries Column -->
            <div class="col-md-8">
                
                <div style="margin-top:3%; text-align:justify;">                
                    <img class="img-responsive" src="img/constantin_pape.jpg" alt="Image of Constantin Pape" style="width:20%;margin:0px 10px" align="left"><br>

                    <p>I am a Juniorprofessor at Georg-August University Göttingen and a member of the <a href="https://uni-goettingen.de/en/619480.html">Institute of Computer Science</a> and <a href="https://www.uni-goettingen.de/en/634473.html">CIDAS</a>. I lead the research group for <b>Computational Cell Analytics</b> since March 2022. My research is focused on deep learning methods for computer vision, in particular segmentation, applied primarily to microscopy images.</p>

                    <p>Previously, I have worked as a PostDoc at EMBL Heidelberg in the group of Anna Kreshuk and did my PhD at the University of Heidelberg under the supervision of Anna Kreshuk and Fred Hamprecht. During my PhD and PostDoc I have mainly worked on instance segmentation problems, with a focus on large volumetric electron microscopy data.</p>
                </div>
            </div> 

            <!-- Contact Info on the Sidebar -->
            <div class="col-md-4">
                <div style="font-family: 'Oswald', sans-serif; font-size: 32px;"><b>Constantin Pape</b></div><br>
                <p><b>constantin.pape@informatik.uni-goettingen.de</b><br>
                <p>Institute of Computer Science<br>
                Georg-August University Göttingen<br>
                <!--
                Street<br>
                City <br>
                Country<br>
                </p>
                -->
            </div>
            
            <!-- Links on the Sidebar -->
            <div class="col-md-4" style="margin-top:2%">
              <dd><a href="https://scholar.google.com/citations?user=idkzOIUAAAAJ&hl=en">Google Scholar</a></dd> 
              <dd><a href="https://github.com/constantinpape">Github</a></dd> 
              <dd><a href="https://twitter.com/cppape">Twitter</a></dd>
            </div>


            <!-- Jobs, thesis, projects -->
            <div class="col-md-8">    
                <h2 id="jobs_thesis">Jobs, thesis, student projects</h2>
                <p>I am looking for a PhD student to work on a project about vision foundation models in bioimage analysis. You can find a description of the project <a href="#foundation-models">here</a>. Please find the official job announcement <a href="https://www.uni-goettingen.de/de/644546.html?details=74113">here</a> and apply via <a href="https://obp.uni-goettingen.de/de-de/OBF/Index/74113">this link</a>.  
                </p>
                <p>I am currenrly not offering any master thesis, bachelor thesis or internship projects, but will offer new projects for the winter term 2023. You can check out an overview of previous projects <a href="https://pad.gwdg.de/s/RbV-wFaX3#">here</a>.
                </p>
            </div>


            <!-- Research -->
            <div class="col-md-8"> 
                <h2 id="research">Research</h2>
                <p>Our group's research goals is to develop deep learning based methods for advanced bioimage analysis. 
                The goals include developing segmentation and tracking methods that require minimal supervision, interactive segmentation and tracking, as well as self-supervised representation learning for bioimage data.
                We are further working on methods for protein structure reconstruction in identification from Cryo-EM and expansion microscopy data, and develop approaches for building shared represetations of imaging, genetic and clinical data.</p>
                
                <p>The adoption of deep learning has improved the quality of image analysis for microscopy dramatically in the last decade.
                In the same period, the throughput, field of view and time resolution in microscopy has increaded significantly, requiring the automation of key analysis steps, such as the identification of cells through segmentation, following cells over time through tracking or classifying cells into distinct states.
                While deep-learning based methods yield high enough quality to achieve automation for many applications they require large amounts of (manually) annotated training data .
                This limitation makes them impractical for applications where no such training data is available and is too costly to create.
                Fortunately, the last years have seen reseach interest in weak supervision, domain adaptation and self-supervision, which promises to make training of high-quality models with significantly less annotated data possible.
                However, these methods are mostly developed for natural images and their adoption in microscopy has so far been limited.
                We aim to bridge this gap, building on initial work for <a href="https://doi.org/10.3389/fcomp.2022.805166">domain adaptation</a>, <a href="https://arxiv.org/abs/2103.14572">weak supervision</a> and even <a href="https://arxiv.org/abs/2107.02600">reinforcement learning</a>.</p>

                <img class="img-responsive" src="img/fig.jpg" alt="Image visualising 4 different image analysis results." style="width:50%;" align="right"><br>
                <p>My previous research has been focused on boundary based instance segmentation. I have developed graph-based methods based on <a href="https://doi.org/10.1038/nmeth.4151">globally optimal graph partitioning</a> and <a href="https://openaccess.thecvf.com/content_ECCV_2018/html/Steffen_Wolf_The_Mutex_Watershed_ECCV_2018_paper.html">fast heuristic partitioning</a>.
                The initial focus of my work has been neuron segmentation in electron micrscopy (D), for which I have developed <a href="https://openaccess.thecvf.com/content_ICCV_2017_workshops/w1/html/Pape_Solving_Large_Multicut_ICCV_2017_paper.html">methods that scale to multi terayte volumes</a> and <a href="https://doi.org/10.3389/fcomp.2019.00006">can incorporate biological priors</a>.
                These methods have been used in various life science applications: <a href="https://doi.org/10.1016/j.cell.2021.07.017">building a high resolution genetic and morphological atlas of P. dumerilii (A)</a >, <a href="https://doi.org/10.1126/science.abj2949">analyzing the morphology of precursor neural cells in sponges (B)</a > or <a href="https://doi.org/10.1002/bies.202000257">developing an imaging based SARS-CoV-2 antibody assay (C)</a >. I plan to continue this work
                and make these methods available through easy-to-use tools in order to democratize the
                access to large-scale volumetric segmentation.</p>

                <p>I am dedicated to open source and open science and am actively contributing to several related efforts. In particular, the <a href="https://bioimage.io/#/">bioimage.io modelzoo</a>, a resource to share deep learning models for microscopy image analysis and <a href="https://doi.org/10.1038/s41592-021-01326-w">ome.ngff</a>, a new image data format that supports efficient storage of large data and on-demand access in the cloud. Furthermore, I co-develop <a
                    href="https://mobie.github.io/">MoBIE</a>, a Fiji plugin for exploring and sharing large multi-modal image data.</p>
            </div>

            <!-- Segment Anything for microscopy project -->
            <div class="col-md-8"> 
                <h3 id="foundation-models">Foundation models for bioimaging</h3>
                <p>Foundation models have become a focus of deep learning research in the last years. The term describes large architectures that were trained on large diverse datasets and can then be applied to solve many different tasks in a given field. These models have first become available in natural language processing (e.g. GPT3 and GPT4), but are now also emerging in computer vision (e.g. <a><href="https://arxiv.org/abs/2103.00020">CLIP</a>).</p>

                <img class="img-responsive" src="img/segment-anything.gif" alt="Applying segment anything to microscopy data, enabling instance segmentation from bounding boxes." style="width:50%;" align="right"><br>
                <p><a href="https://segment-anything.com/">Segment Anything</a>, a recently published vision foundation model, enables fully automated and interactive instance segmentation and works for a wide set of image modalities. We have found that it works well for microscopy data, even without further fine-tuning, and can speed up data annotation significantly. Motivated by this finding we are now developing <a href="https://github.com/computational-cell-analytics/micro-sam">Segment
                    Anything for Microscopy</a>, a data annotation tool for biologists. The animation shows how it is ued to interactively segment cells from bounding box annotations.</p>

                <p>The goal of this project is to further improve foundation models like Segment Anything for bioimaging data and develop them into an universal solution for segmentation and tracking problems. To achieve this goal you will:
                <ul>
                    <li>Develop methods to fine-tune Segment Anything (or similar models) on large microscopy datasets to improve their performance for our target applications. Building on recent methods for fine-tuning language foundation models such as <a href="https://arxiv.org/abs/2106.09685">LoRA</a>.</li>
                    <li>Implement few-shot segmentation approaches that enable learning from interactive segmentation results and using them for automatic segmentation (and tracking) without having to train a new model.</li>
                    <li>Build and improve tools for interactive segmentation and tracking based on (fine-tuned) vision foundation models.</li>
                </ul>
                </p>

                <p>This project is funded by the Multiscale Bioimaging Cluster of Excellence (<a href="https://mbexc.de/de/">MBExC</a>). The methods will be developed in collaboration with other research groups within MBExC and will be applied to solve challenging image analysis problems they are facing.</p> 
            
            </div>
            
            <!-- Teaching -->
            <div class="col-md-8">
                <h2 id="teaching">Teaching</h2>
                <p>I hold a lecture on deep learning and offer seminars on applications of deep learning at the University of Göttingen. See the next paragraph for a short overview of these courses and check out <a href="http://cs.ugoe.de/pape">UniVZ</a> for the courses currently offered.</p>
                <p>In addition to teaching at the university I co-organize the Deep Learning for Image Analysis course at EMBL, see <a href="https://www.embl.org/about/info/course-and-conference-office/events/mac23-01/">the last course page</a> for details. I am also a <a href="https://mbexc.de/careers/hertha-sponer-college">Hertha Sponer College Instructor</a>, where I teach a course on advanced image analysis (course details will follow soon).</p>

                <h3 id="dl-for-cv">Deep Learning for Computer Vision</h3>
                <p>This lecture introduces the fundamentals of deep learning (artificial neural networks, training via stochastic gradient descent), explains convolutional neural networks and their applications to computer vision tasks like image classification, segmentation and object detection. It also introduces generative methods for tasks like neural style transfer or image synthesis and covers advanced topics such as vision transformers. The lecture is held every winter term
                and consists of lectures and exercises. You can find its module description <a href="https://flexnow2.uni-goettingen.de/modulbeschreibungen/91183.pdf">here</a>.</p>
                
                <h3 id="dl-for-cv">Deep Learning in Biology and Medicine</h3>
                <p>This seminar discusses advanced topics in applications of deep learning methods in biology and medicine. We cover applications in image analysis, structural biology (e.g. protein folding with Alpha Fold), large language models in medicine and more. The seminar is offered every summer term.</p>
            </div>
            
            
            <!-- Publications -->
            <div class="col-md-8">    
                <h2 id="publications">Publications</h2>
                
                Please find the full list of publications on <a href="https://scholar.google.com/citations?user=idkzOIUAAAAJ&hl=en">Google Scholar</a>. Below is a list of selected publications:
                <p><b>From our group:</b>
                <ul>
                <li class="paper"><a href="https://arxiv.org/abs/2303.11790">Probabilistic Domain Adaptation for Biomedical Image Segmentation, arXiv (2023)</a>, Archit and Pape</li>
                </ul>
                </p>

                <p><b>From my PhD and PostDoc:</b>
                <ul>
                <li class="paper"><a href="https://www.nature.com/articles/s41592-023-01776-4">MoBIE: a Fiji plugin for sharing and exploration of multi-modal cloud-hosted big image data, Nature Methods (2023)</a>, Pape, Meechan et al.</li>
                <li class="paper"><a href="https://doi.org/10.3389/fcomp.2022.805166">From Shallow to Deep: Exploiting Feature-Based Classifiers for Domain Adaptation in Semantic Segmentation, Frontiers in Computer Science (2022)</a>, Matskevych, Wolny, Pape and Kreshuk</li>
                <li class="paper"><a href="https://doi.org/10.1126/science.abj2949">Profiling cellular diversity in sponges informs animal cell type and nervous system evolution, Science (2021)</a>, Musser, Schippers, Mizzon, Kohn, Pape et al.</li>
                <li class="paper"><a href="https://doi.org/10.1016/j.cell.2021.07.017">Whole-body integration of gene expression and single-cell morphology, Cell (2021)</a>, Vergara, Pape, Meechan et al.</li>
                <li class="paper"><a href="https://doi.org/10.1002/bies.202000257">Microscopy-based assay for semi-quantitative detection of SARS-CoV-2 specific antibdoes in human sera, BioEssays (2021)</a>, Pape, Remme et al.</li>
                <li class="paper"><a href="https://doi.org/10.3389/fcomp.2019.00006">Leveraging domain Knowledge to improve microscopy image segmentation with lifted multicuts, Frontiers in Computer Science (2019)</a>, Pape et al.</li>
                <li class="paper"><a href="https://openaccess.thecvf.com/content_ECCV_2018/html/Steffen_Wolf_The_Mutex_Watershed_ECCV_2018_paper.html">The mutex watershed: efficient, paramter-free image partitioing, ECCV (2018)</a>, Wolf, Pape et al.</li>
                <li class="paper"><a href="https://openaccess.thecvf.com/content_ICCV_2017_workshops/w1/html/Pape_Solving_Large_Multicut_ICCV_2017_paper.html">Solving large multicut problems for connectomics via domain decomposition, ICCV Workshops (2017)</a>, Pape et al.</li>
                <li class="paper"><a href="https://doi.org/10.1038/nmeth.4151">Multicut brings automated neurite segmentation closer to human performance, Nature Methods (2017)</a>, Beier, Pape et al.</li>
                </ul>
                <p>
            
            </div>
            

            <!-- CV -->
            <div class="col-md-8">    
                <h2 id="cv">CV</h2>
                
                <ul>
                <li>2010-2013 Bachelor of Science, Physics, Ruprecht-Karls University Heidelberg</li>
                <li>2013-2016 Master of Science, Physics, Ruprecht-Karls University Heidelberg</li>
                <li>2016-2021 PhD, Physics, Ruprecht-Karls University Heidelberg
                    <ul>
                    <li>2017-2018 Visiting scientist, Janelia Research Campus</li>
                    <li>2018-2021 Visiting scientist, EMBL Heidelberg
                    </ul>
                </li>
                <li>2021-2022 PostDoctoral Fellow, EMBL Heidelberg</li>
                <li>2022- Juniorprofessor, Georg-August University Goettingen</li>
                </ul>
            
            </div>
            
        </div>


    </div>
    <!-- /.container -->
    
    <!-- Other people may like it too! -->
    <a style="color:#b5bec9;font-size:0.8em; float:right;" href="https://github.com/mavroudisv/plain-academic">Plain Academic</a> 
    
</body>

</html>
